{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating Predictions\n",
    "\n",
    "We load the models and test data from the designated directories and then predict the sales for those days. The individual category-level (such as a single store/department/state/category) model predictions are concatenated to give us the whole set of forecasts. \n",
    "\n",
    "### Ensembling\n",
    "We tried to ensemble all the model predictions present at our disposal, using simple averages and weighted averages (where the weights are model errors). We find the best model ensemble gives us a WRMSSE of 0.55."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "import pickle\n",
    "import random\n",
    "from itertools import product\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "SEED = 42\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_DIR = \"../../\"\n",
    "MODEL_NAME = \"lgb\"\n",
    "TEST_DATA_DIR = BASE_DIR + f\"models/{MODEL_NAME}/\"\n",
    "MODELS_DIR = BASE_DIR + f\"models/{MODEL_NAME}/\"\n",
    "MODEL_FILE_PREFIX = f\"{MODEL_NAME}_model_\"\n",
    "\n",
    "TARGET_COL = \"units_sold\"\n",
    "PRED_LENGTH = 28\n",
    "\n",
    "TRAIN_END = 1941\n",
    "\n",
    "# Change this list to lists we want to iterate through (unique values in the hierarchical columns)\n",
    "CATEGORIES = ['HOBBIES', 'HOUSEHOLD', 'FOODS']\n",
    "STATES = [\"CA\",\"TX\",\"WI\"]\n",
    "STORES = [\"CA_1\", \"CA_2\", \"CA_3\", \"CA_4\", \"TX_1\", \"TX_2\", \"TX_3\", \"WI_1\", \"WI_2\", \"WI_3\"]\n",
    "DEPTS = ['HOBBIES_1', 'HOBBIES_2', 'HOUSEHOLD_1', 'HOUSEHOLD_2', 'FOODS_1' ,'FOODS_2','FOODS_3']\n",
    "\n",
    "HIERARCHY_COL = [\"state_id\",\"cat_id\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_day_cols = [f'F{day}' for day in range(1,29)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_list  = list(product(STORES, DEPTS))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_predictions(col_list=col_list):\n",
    "    # initialising submission df --> storing predictions in submission compatible format\n",
    "    submission_df = pd.DataFrame()\n",
    "    col_ids = [\"_\".join(i) for i in col_list]\n",
    "    for col_id in col_ids:\n",
    "        print(f\"Generating Predicitons for {col_id}\")\n",
    "        test = pd.read_pickle(TEST_DATA_DIR+\"test_data_\"+col_id+\".pkl\")\n",
    "        \n",
    "        # Subsetting to only validation or evaluation rows \n",
    "        validation_indices = (test['d']>TRAIN_END-PRED_LENGTH) & (test['d']<=TRAIN_END)\n",
    "        evaluation_indices = (test['d']>TRAIN_END) & (test['d']<=TRAIN_END+PRED_LENGTH)\n",
    "        test = test[validation_indices+evaluation_indices]\n",
    "        test.drop(columns=[TARGET_COL], inplace=True)\n",
    "        # loading the model and predicting to populate target column\n",
    "        with open(MODELS_DIR+MODEL_FILE_PREFIX+col_id+\".pkl\", \"rb\") as f:\n",
    "            model = pickle.load(f)\n",
    "        test[TARGET_COL] = model.predict(test.drop(columns=[\"id\"]))\n",
    "        # columns other than id,d,units_sold are only needed till predictions\n",
    "        test = test[[\"d\",TARGET_COL,\"id\"]]\n",
    "\n",
    "        # Adjusting the id names\n",
    "        test.loc[validation_indices,\"id\"] = test.loc[validation_indices,\"id\"].str.replace(\"evaluation\",\"validation\")\n",
    "\n",
    "        # reformatting the predictions (each id is a row)\n",
    "        id_list = test[\"id\"].unique()\n",
    "        submission_subset = pd.DataFrame(index=id_list, columns=submission_day_cols)\n",
    "        submission_subset.index.name = \"id\"\n",
    "        for id in id_list:\n",
    "            current_id_indices = test[\"id\"]==id\n",
    "            submission_subset.loc[id, submission_day_cols] = test.loc[current_id_indices,\"units_sold\"].values\n",
    "        submission_df = pd.concat([submission_df,submission_subset])\n",
    "        del submission_subset, test\n",
    "    return submission_df.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating Predicitons for CA_1_HOBBIES_1\n",
      "Generating Predicitons for CA_1_HOBBIES_2\n",
      "Generating Predicitons for CA_1_HOUSEHOLD_1\n",
      "Generating Predicitons for CA_1_HOUSEHOLD_2\n",
      "Generating Predicitons for CA_1_FOODS_1\n",
      "Generating Predicitons for CA_1_FOODS_2\n",
      "Generating Predicitons for CA_1_FOODS_3\n",
      "Generating Predicitons for CA_2_HOBBIES_1\n",
      "Generating Predicitons for CA_2_HOBBIES_2\n",
      "Generating Predicitons for CA_2_HOUSEHOLD_1\n",
      "Generating Predicitons for CA_2_HOUSEHOLD_2\n",
      "Generating Predicitons for CA_2_FOODS_1\n",
      "Generating Predicitons for CA_2_FOODS_2\n",
      "Generating Predicitons for CA_2_FOODS_3\n",
      "Generating Predicitons for CA_3_HOBBIES_1\n",
      "Generating Predicitons for CA_3_HOBBIES_2\n",
      "Generating Predicitons for CA_3_HOUSEHOLD_1\n",
      "Generating Predicitons for CA_3_HOUSEHOLD_2\n",
      "Generating Predicitons for CA_3_FOODS_1\n",
      "Generating Predicitons for CA_3_FOODS_2\n",
      "Generating Predicitons for CA_3_FOODS_3\n",
      "Generating Predicitons for CA_4_HOBBIES_1\n",
      "Generating Predicitons for CA_4_HOBBIES_2\n",
      "Generating Predicitons for CA_4_HOUSEHOLD_1\n",
      "Generating Predicitons for CA_4_HOUSEHOLD_2\n",
      "Generating Predicitons for CA_4_FOODS_1\n",
      "Generating Predicitons for CA_4_FOODS_2\n",
      "Generating Predicitons for CA_4_FOODS_3\n",
      "Generating Predicitons for TX_1_HOBBIES_1\n",
      "Generating Predicitons for TX_1_HOBBIES_2\n",
      "Generating Predicitons for TX_1_HOUSEHOLD_1\n",
      "Generating Predicitons for TX_1_HOUSEHOLD_2\n",
      "Generating Predicitons for TX_1_FOODS_1\n",
      "Generating Predicitons for TX_1_FOODS_2\n",
      "Generating Predicitons for TX_1_FOODS_3\n",
      "Generating Predicitons for TX_2_HOBBIES_1\n",
      "Generating Predicitons for TX_2_HOBBIES_2\n",
      "Generating Predicitons for TX_2_HOUSEHOLD_1\n",
      "Generating Predicitons for TX_2_HOUSEHOLD_2\n",
      "Generating Predicitons for TX_2_FOODS_1\n",
      "Generating Predicitons for TX_2_FOODS_2\n",
      "Generating Predicitons for TX_2_FOODS_3\n",
      "Generating Predicitons for TX_3_HOBBIES_1\n",
      "Generating Predicitons for TX_3_HOBBIES_2\n",
      "Generating Predicitons for TX_3_HOUSEHOLD_1\n",
      "Generating Predicitons for TX_3_HOUSEHOLD_2\n",
      "Generating Predicitons for TX_3_FOODS_1\n",
      "Generating Predicitons for TX_3_FOODS_2\n",
      "Generating Predicitons for TX_3_FOODS_3\n",
      "Generating Predicitons for WI_1_HOBBIES_1\n",
      "Generating Predicitons for WI_1_HOBBIES_2\n",
      "Generating Predicitons for WI_1_HOUSEHOLD_1\n",
      "Generating Predicitons for WI_1_HOUSEHOLD_2\n",
      "Generating Predicitons for WI_1_FOODS_1\n",
      "Generating Predicitons for WI_1_FOODS_2\n",
      "Generating Predicitons for WI_1_FOODS_3\n",
      "Generating Predicitons for WI_2_HOBBIES_1\n",
      "Generating Predicitons for WI_2_HOBBIES_2\n",
      "Generating Predicitons for WI_2_HOUSEHOLD_1\n",
      "Generating Predicitons for WI_2_HOUSEHOLD_2\n",
      "Generating Predicitons for WI_2_FOODS_1\n",
      "Generating Predicitons for WI_2_FOODS_2\n",
      "Generating Predicitons for WI_2_FOODS_3\n",
      "Generating Predicitons for WI_3_HOBBIES_1\n",
      "Generating Predicitons for WI_3_HOBBIES_2\n",
      "Generating Predicitons for WI_3_HOUSEHOLD_1\n",
      "Generating Predicitons for WI_3_HOUSEHOLD_2\n",
      "Generating Predicitons for WI_3_FOODS_1\n",
      "Generating Predicitons for WI_3_FOODS_2\n",
      "Generating Predicitons for WI_3_FOODS_3\n"
     ]
    }
   ],
   "source": [
    "df = get_predictions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(BASE_DIR+\"/submissions/store_dept_lgb_pred_v1.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "BASE_DIR = \"../../\"\n",
    "submission_day_cols = [f'F{day}' for day in range(1,29)]\n",
    "\n",
    "## Basic Ensembling\n",
    "xgb = pd.read_csv(BASE_DIR+\"/submissions/store_xgb_pred.csv\").sort_values(\"id\")\n",
    "w1 = 1/1#0.6211\n",
    "lgb_store = pd.read_csv(BASE_DIR+\"/submissions/store_lgb_pred_v2.csv\").sort_values(\"id\")\n",
    "w2 = 1/1#0.62292\n",
    "lgb_state_cat = pd.read_csv(BASE_DIR+\"/submissions/state_cat_lgb_pred_v1.csv\").sort_values(\"id\")\n",
    "w3 = 1/1#0.64231\n",
    "lgb_store_cat = pd.read_csv(BASE_DIR+\"/submissions/store_cat_lgb_pred_v1.csv\").sort_values(\"id\")\n",
    "w4 = 1/1#0.62917\n",
    "lgb_dept = pd.read_csv(BASE_DIR+\"/submissions/dept_lgb_pred_v1.csv\").sort_values(\"id\")\n",
    "w5 = 1/1#2.13755\n",
    "lgb_dept = pd.read_csv(BASE_DIR+\"/submissions/store_dept_lgb_pred_v1.csv\").sort_values(\"id\")\n",
    "w5 = 1/1#0.52978\n",
    "\n",
    "ensemble = pd.DataFrame(columns=xgb.columns, index=xgb.index)\n",
    "ensemble[submission_day_cols] = (xgb.iloc[:,1:]*w1\n",
    "                                + lgb_store.iloc[:,1:]*w2\n",
    "                                + lgb_state_cat.iloc[:,1:]*w3\n",
    "                                + lgb_store_cat.iloc[:,1:]*w4\n",
    "                                + lgb_dept.iloc[:,1:]*w5\n",
    "                                    )/(w1+w2+w3+w4+w5)\n",
    "ensemble[\"id\"] = xgb[\"id\"]\n",
    "\n",
    "ensemble.to_csv(BASE_DIR+\"/submissions/ensemble_basic_v9.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5290aa75faf23a16319909e19adc2cd8a2a5bf93f1976f81386266c3c2bf7942"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
